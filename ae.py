# -*- coding: utf-8 -*-
"""AE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AU3CAS5IhSzhNm-Ae7RuAoN7AKvZYkCc

Question 1 (Dataset preprocessing)
"""

import csv, random
from sklearn.model_selection import train_test_split
from collections import Counter
random.seed(42)

cartman = []
with open('cartman.csv') as c_f:
  c_r = csv.reader(c_f)
  for row in c_r:
    cartman.append({'name':'Cartman', 'line':''.join(row)})
cartman = random.sample(cartman, 2000)

kenny = []
with open('kenny.csv') as ke_f:
  ke_r = csv.reader(ke_f)
  for row in ke_r:
    kenny.append({'name':'Kenny', 'line':''.join(row)})

kyle = []
with open('kyle.csv') as ky_f:
  ky_r = csv.reader(ky_f)
  for row in ky_r:
    kyle.append({'name':'Kyle', 'line':''.join(row)})
kyle = random.sample(kyle, 2000)

stan = []
with open('stan.csv') as s_f:
  s_r = csv.reader(s_f)
  for row in s_r:
    stan.append({'name':'Stan', 'line':''.join(row)})
stan = random.sample(stan, 2000)

data = cartman + kenny + kyle + stan

labels, texts = [], []
for val in data:
  labels.append(val['name'])
  texts.append(val['line'])

texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, test_size=0.2, random_state=42)
texts_train, texts_val, labels_train, labels_val = train_test_split(texts_train, labels_train, test_size=0.25, random_state=42)

Counter(labels_train)

"""Question 2 (K-means clustering)"""

#Vectorise
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
X_train = vectorizer.fit_transform(texts_train)
X_val = vectorizer.transform(texts_val)

print(X_train[0].shape)

import numpy as np

def k_means(X, k):
    np.random.seed(42)
    centroids = X[np.random.choice(len(X), size=k, replace=False)]
    labels = np.zeros(len(X))
    
    while(True):
        distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))
        new_labels = np.argmin(distances, axis=0)
        
        if np.array_equal(labels, new_labels):
            break
        
        for i in range(k):
            centroids[i] = X[new_labels == i].mean(axis=0)
        
        labels = new_labels
    
    return labels, centroids

k_labels, centroids = k_means(X_train.toarray(), 5)

Counter(k_labels)

for j in range (5):
  counter, i = 0, 0
  while (counter < 10):
    if (k_labels[i] == j):
      unvectorized = vectorizer.inverse_transform(X_train[i])
      for text in unvectorized:
        print(' '.join(text))
      counter+=1
    i+=1
  print()

from scipy import sparse

array = X_train.toarray()
for j in range (5):
  split = array[k_labels==j]
  mean = np.mean(split, axis=0)
  ind = np.argpartition(mean, -5)[-5:]
  for i in ind:
    a = np.zeros_like(mean)
    a[i] = 1
    sA = sparse.csr_matrix(a)
    unvectorized = vectorizer.inverse_transform(sA)
    for text in unvectorized:
      print(' '.join(text))
  print()

from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

string_k_labels = []
for val in k_labels:
  if (val == 0):
    string_k_labels.append("Cartman")
  elif (val == 1):
    string_k_labels.append("Stan")
  elif (val == 2):
    string_k_labels.append("Kenny")
  elif (val == 3):
    string_k_labels.append("Kyle")
  elif (val == 4):
    string_k_labels.append("Unknown")
  
cm = confusion_matrix(labels_train, string_k_labels)
ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Cartman','Stan', 'Kenny', 'Kyle', 'Unknown']).plot()

#Dummy classifier "most_frequent"
from sklearn.dummy import DummyClassifier
import numpy as np

dummy_mf = DummyClassifier(strategy="most_frequent", random_state=42)
dummy_mf.fit(X_train, labels_train)
dummy_mf_labels_predicted = dummy_mf.predict(X_val)

len(dummy_mf_labels_predicted)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

dummy_mf_accuracy = accuracy_score(labels_val, dummy_mf_labels_predicted)
print(f"{dummy_mf_accuracy=:.3f}")

dummy_mf_precision = precision_score(labels_val, dummy_mf_labels_predicted)
print(f"{dummy_mf_precision=:.3f}")

dummy_mf_recall = recall_score(labels_val, dummy_mf_labels_predicted)
print(f"{dummy_mf_recall=:.3f}")

dummy_mf_f1 = f1_score(labels_val, dummy_mf_labels_predicted)
print(f"{dummy_mf_f1=:.3f}")

#Dummy classifier "stratified"
from sklearn.dummy import DummyClassifier
import numpy as np

dummy_s = DummyClassifier(strategy="stratified", random_state=42)
dummy_s.fit(X_train, labels_train)
dummy_s_labels_predicted = dummy_s.predict(X_val)

len(dummy_s_labels_predicted)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

dummy_s_accuracy = accuracy_score(labels_val, dummy_s_labels_predicted)
print(f"{dummy_s_accuracy=:.3f}")

dummy_s_precision = precision_score(labels_val, dummy_s_labels_predicted)
print(f"{dummy_s_precision=:.3f}")

dummy_s_recall = recall_score(labels_val, dummy_s_labels_predicted)
print(f"{dummy_s_recall=:.3f}")

dummy_s_f1 = f1_score(labels_val, dummy_s_labels_predicted)
print(f"{dummy_s_f1=:.3f}")

#LogisticRegression One-Hot
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import CountVectorizer

one_vectorizer = CountVectorizer(binary=True)
one_X_train = one_vectorizer.fit_transform(texts_train)
one_X_val = one_vectorizer.transform(texts_val)

clf_one = LogisticRegression(random_state=42)
clf_one.fit(one_X_train,labels_train)
clf_one_labels_predicted = clf_one.predict(one_X_val)

len(clf_one_labels_predicted)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

clf_one_accuracy = accuracy_score(labels_val, clf_one_labels_predicted)
print(f"{clf_one_accuracy=:.3f}")

clf_one_precision = precision_score(labels_val, clf_one_labels_predicted)
print(f"{clf_one_precision=:.3f}")

clf_one_recall = recall_score(labels_val, clf_one_labels_predicted)
print(f"{clf_one_recall=:.3f}")

clf_one_f1 = f1_score(labels_val, clf_one_labels_predicted)
print(f"{clf_one_f1=:.3f}")

#LogisticRegression TF-IDF
from sklearn.linear_model import LogisticRegression

clf_tfidf = LogisticRegression(random_state=42)
clf_tfidf.fit(X_train,labels_train)
clf_tfidf_labels_predicted = clf_tfidf.predict(X_val)

len(clf_tfidf_labels_predicted)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

clf_tfidf_accuracy = accuracy_score(labels_val, clf_tfidf_labels_predicted)
print(f"{clf_tfidf_accuracy=:.3f}")

clf_tfidf_precision = precision_score(labels_val, clf_tfidf_labels_predicted)
print(f"{clf_tfidf_precision=:.3f}")

clf_tfidf_recall = recall_score(labels_val, clf_tfidf_labels_predicted)
print(f"{clf_tfidf_recall=:.3f}")

clf_tfidf_f1 = f1_score(labels_val, clf_tfidf_labels_predicted)
print(f"{clf_tfidf_f1=:.3f}")

#SVC
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

clf_svc = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))
clf_svc.fit(one_X_train, labels_train)
clf_svc_labels_predicted = clf_svc.predict(X_val)

len(clf_svc_labels_predicted)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

clf_svc_accuracy = accuracy_score(labels_val, clf_svc_labels_predicted)
print(f"{clf_svc_accuracy=:.3f}")

clf_svc_precision = precision_score(labels_val, clf_svc_labels_predicted)
print(f"{clf_svc_precision=:.3f}")

clf_svc_recall = recall_score(labels_val, clf_svc_labels_predicted)
print(f"{clf_svc_recall=:.3f}")

clf_svc_f1 = f1_score(labels_val, clf_svc_labels_predicted)
print(f"{cls_svc_f1=:.3f}")